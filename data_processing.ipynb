{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import logging\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATA_RAW = \"../data_raw/\"\n",
    "FOLDER_DATA_PROCESSED = \"../data_processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions\n",
    "\n",
    "This section contains utility functions for processing and cleaning user interaction data, including timestamp conversion, session duration calculation, outlier filtering, and feature engineering for course recommendation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp Processing\n",
    "\n",
    "Convert the 'timestamp' column to datetime format and handle missing or invalid timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_tranform(df):\n",
    "    ## Transform column \"timestamp\" to date type\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    ## Review if some row does not have timestamp\n",
    "    print(\"========= Null timestamp ==============\")\n",
    "    print(df[df['timestamp'].isnull()])\n",
    "    print(\"=======================================\")\n",
    "    df.dropna(subset=['timestamp'],inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Session Duration\n",
    "\n",
    "Functions to compute the duration of user sessions and handle missing or negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(x, user_data):\n",
    "    try:\n",
    "        if x.name != 0 and x.name < user_data.shape[0]:\n",
    "            last_log = user_data.iloc[(x.name - 1)]\n",
    "            if last_log[\"id_session\"] == x[\"id_session\"]:\n",
    "                return int(pd.Timedelta(x[\"timestamp\"] - last_log[\"timestamp\"]).total_seconds() / 60)\n",
    "            else:\n",
    "                return -5\n",
    "        else:\n",
    "            return -5\n",
    "    except:\n",
    "        logging.debug('error get duration lesson: {}'.format(x[\"lesson_name\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_negative_duration(x, dataframe_lessons_duration):\n",
    "    try:\n",
    "        if x.duration == -5:\n",
    "            return dataframe_lessons_duration[dataframe_lessons_duration[\"lesson_name\"] == x[\"lesson_name\"]][\"duration\"].values[0]\n",
    "        else:\n",
    "            return x.duration\n",
    "    except:\n",
    "        logging.debug('error replace negative duration: {}'.format(x[\"lesson_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_duration(user_data):\n",
    "\n",
    "    ## Load data set of lesson duration \n",
    "    courses_avg_duration_df = pd.read_csv(f\"{FOLDER_DATA_RAW}courses_avg_duration.csv\",encoding_errors='ignore')\n",
    "    courses_avg_duration_df[\"duration\"] = courses_avg_duration_df.groupby(\"lesson_name\")[\"duration\"].transform('mean')\n",
    "    courses_avg_duration_df[\"duration\"] = courses_avg_duration_df[\"duration\"]/60\n",
    "    courses_avg_duration_df.drop_duplicates(subset=[\"lesson_name\"], inplace=True)\n",
    "    print(\"=== describe mean general lesson duration =====\")\n",
    "    print(courses_avg_duration_df[\"duration\"].describe())\n",
    "    print(\"=======================================\")\n",
    "    ## Apply functions to get duration (return -5 if can't get duration)\n",
    "    user_data = user_data.sort_values(by=[\"id_session\",\"timestamp\"]).reset_index(drop=True)\n",
    "    user_data[\"duration\"] = user_data.apply(lambda x:get_duration(x,user_data), axis=1)\n",
    "\n",
    "    print(\"== describe mean lesson duration ==\")\n",
    "    print(user_data[user_data[\"duration\"] >= 0][\"duration\"].describe())\n",
    "    print(\"===========================================\")\n",
    "\n",
    "    user_data[\"duration\"] = user_data.apply(lambda x:replace_negative_duration(x,courses_avg_duration_df), axis=1)\n",
    "\n",
    "    print(\"== describe mean lesson duration (without -5) ==\")\n",
    "    print(user_data[\"duration\"].describe())\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    user_data[\"duration_intra\"] = user_data.groupby([\"id_session\", \"lesson_name\"])[\"duration\"].transform('sum')\n",
    "\n",
    "    print(\"== describe intra-lesson duration ==\")\n",
    "    print(user_data[\"duration\"].describe())\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    user_data[\"duration_inter\"] = user_data.groupby([\"user_id\", \"lesson_name\"])[\"duration\"].transform('sum')\n",
    "\n",
    "    print(\"== describe inter-lesson duration ==\")\n",
    "    print(user_data[\"duration_inter\"].describe())\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    return user_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Data (Remove Outliers)\n",
    "\n",
    "Remove users with too few or too many courses viewed to reduce noise and outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users(df):\n",
    "    df[\"courses_viewed\"] = df.groupby(\"user_id\")[\"course_name\"].transform('nunique')\n",
    "    df = df[df[\"courses_viewed\"] > 2]\n",
    "    df = df[df[\"courses_viewed\"] < 50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Total Lessons per Course\n",
    "\n",
    "Merge the dataset with course information to include the total number of lessons for each course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lessons_by_course(df):\n",
    "    courses_info = pd.read_csv(f\"{FOLDER_DATA_RAW}lessons_by_course.csv\", sep=\",\")\n",
    "    print(\"==== Mean duration by course ==========\")\n",
    "    print(courses_info[\"lessons_number\"].describe())\n",
    "    print(\"=======================================\")\n",
    "    final_data_set = pd.merge(df, courses_info, how='left', left_on='course_name', right_on='path_course').drop(columns = ['path_course'])\n",
    "    final_data_set = final_data_set.dropna(subset=['lessons_number'])\n",
    "    return final_data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Course Data per User\n",
    "\n",
    "Compute features such as the number of lessons viewed and course completion percentage for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_courses_by_user(df):\n",
    "    df[\"lessons_viewed\"] = df.groupby([\"user_id\",\"course_name\"])[\"course_name\"].transform('nunique')\n",
    "    df[\"course_porcentage\"] = df[\"lessons_viewed\"] / df[\"lessons_number\"]\n",
    "    df[\"course_porcentage_mean\"] = df.drop_duplicates(subset=[\"user_id\", \"course_name\"]).groupby(\"user_id\")[\"course_porcentage\"].transform('mean')\n",
    "    df[\"course_porcentage_mean_global\"] = df.drop_duplicates(subset=[\"user_id\", \"course_name\"]).groupby(\"course_name\")[\"course_porcentage\"].transform('mean')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data into Train and Test Sets\n",
    "\n",
    "Functions to split the processed data into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number the courses for a specific user\n",
    "def create_index(df, user_id):\n",
    "    df_courses_index=df.loc[df['user_id']== user_id].reset_index().reset_index()\n",
    "    df_courses_index[\"position\"]=df_courses_index[\"level_0\"]\n",
    "    df_courses_index=df_courses_index.drop(columns=[\"level_0\", \"index\"])\n",
    "    df_courses_index[\"position\"]=df_courses_index[\"position\"]+1\n",
    "    \n",
    "    return df_courses_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function classifies between train and test\n",
    "def clasificator(index , courses_viewed):\n",
    "    return \"test\" if index>(math.floor(courses_viewed *0.7)) else \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_sets(df):\n",
    "    frames_train=[]\n",
    "    frames_test=[]\n",
    "\n",
    "    #Iterate through each user, classifying rows as train or test\n",
    "    for i in df[\"user_id\"].unique():\n",
    "        data_user=create_index(df, i)\n",
    "        data_user[\"clasification\"]=data_user.apply(lambda x:clasificator(x[\"position\"], x[\"courses_viewed\"]), axis =1)\n",
    "\n",
    "        frames_train.append(data_user[data_user[\"clasification\"]==\"train\"])\n",
    "        frames_test.append(data_user[data_user[\"clasification\"]==\"test\"])\n",
    "\n",
    "    df_train=pd.concat(frames_train)\n",
    "    df_test=pd.concat(frames_test)\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline\n",
    "\n",
    "This section executes the full data processing pipeline, including loading, cleaning, feature engineering, and splitting the data for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"data_processing.log\",\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Null timestamp ==============\n",
      "                    user_id  id_session course_name lesson_name timestamp\n",
      "544911  10174768.1627523178  1627523178          nv          tc       NaT\n",
      "544912  10174768.1627523178  1627523178          nv          tc       NaT\n",
      "=======================================\n",
      "=== describe mean general lesson duration =====\n",
      "count    2527.000000\n",
      "mean        4.266185\n",
      "std         6.356358\n",
      "min         0.004167\n",
      "25%         1.078199\n",
      "50%         2.513435\n",
      "75%         5.495256\n",
      "max       133.765785\n",
      "Name: duration, dtype: float64\n",
      "=======================================\n",
      "== describe mean lesson duration ==\n",
      "count    397003.000000\n",
      "mean          2.781679\n",
      "std           5.408902\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           3.000000\n",
      "max          97.000000\n",
      "Name: duration, dtype: float64\n",
      "===========================================\n",
      "== describe mean lesson duration (without -5) ==\n",
      "count    608271.000000\n",
      "mean          4.389959\n",
      "std           6.358481\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.837006\n",
      "75%           6.892560\n",
      "max         133.765785\n",
      "Name: duration, dtype: float64\n",
      "=======================================\n",
      "== describe intra-lesson duration ==\n",
      "count    608271.000000\n",
      "mean          4.389959\n",
      "std           6.358481\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.837006\n",
      "75%           6.892560\n",
      "max         133.765785\n",
      "Name: duration, dtype: float64\n",
      "=======================================\n",
      "== describe inter-lesson duration ==\n",
      "count    608144.000000\n",
      "mean         18.659200\n",
      "std          55.717586\n",
      "min           0.000000\n",
      "25%           1.716980\n",
      "50%           7.341927\n",
      "75%          18.649944\n",
      "max        1861.955208\n",
      "Name: duration_inter, dtype: float64\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv(f\"{FOLDER_DATA_RAW}raw_information_user.csv\", sep=\",\", usecols=[\"user_id\", \"course_name\",\"id_session\" ,\"lesson_name\",\"timestamp\"],low_memory=False)\n",
    "user_data = timestamp_tranform(user_data)\n",
    "user_data = process_duration(user_data)\n",
    "user_data.dropna(subset=['lesson_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extra step to delete courses that are not included in the CB system, reduce original size reported in the paper\n",
    "course_list = np.load(f\"{FOLDER_DATA_PROCESSED}listcourses.npy\")\n",
    "user_data = user_data[user_data[\"course_name\"].isin(course_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Mean duration by course ==========\n",
      "count    291.000000\n",
      "mean      11.563574\n",
      "std        9.782739\n",
      "min        0.000000\n",
      "25%        4.000000\n",
      "50%        8.000000\n",
      "75%       18.000000\n",
      "max       39.000000\n",
      "Name: lessons_number, dtype: float64\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "user_data = add_lessons_by_course(user_data)\n",
    "user_data = get_data_courses_by_user(user_data)\n",
    "user_data = filter_users(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Users number ===========\n",
      "6863\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "print(\"========= Users number ===========\")\n",
    "print(user_data[\"user_id\"].nunique())\n",
    "print(\"=================================\")\n",
    "user_data.to_csv(f'{FOLDER_DATA_PROCESSED}final_data_set.csv')\n",
    "\n",
    "user_data_reduce = user_data.drop_duplicates(subset=[\"user_id\", \"course_name\"])\n",
    "\n",
    "df_train, df_test = split_data_sets(user_data_reduce)\n",
    "df_test.to_csv(f'{FOLDER_DATA_PROCESSED}dataTest.csv')\n",
    "df_train.to_csv(f'{FOLDER_DATA_PROCESSED}dataTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_list = np.load(f\"{FOLDER_DATA_PROCESSED}listcourses.npy\")\n",
    "data = pd.read_csv(f\"{FOLDER_DATA_PROCESSED}final_data_set.csv\", sep=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(course_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"course_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55453"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"id_session\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
